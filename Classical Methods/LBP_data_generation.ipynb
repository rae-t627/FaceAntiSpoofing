{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from PIL import Image\n",
    "import copy\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPLAY ATTACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder,l):\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = 64\n",
    "    for label in os.listdir(folder):\n",
    "        \n",
    "        label_path = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_path):\n",
    "\n",
    "            for filename in os.listdir(label_path):\n",
    "\n",
    "                img_path = os.path.join(label_path, filename)\n",
    "                if img_path.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                    \n",
    "                    img = cv2.resize(cv2.imread(img_path),(size,size))\n",
    "                    if img is not None:\n",
    "\n",
    "                        images.append(img)\n",
    "                        labels.append(l)\n",
    "                    \n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Train Dataset real\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\train\\real\"\n",
    "replay_img_real_train, replay_label_r_train = load_images_from_folder(path, 1)\n",
    "\n",
    "# Train Dataset attack\n",
    "\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\train\\attack\\hand\"\n",
    "replay_img_spoof_train_hand, replay_label_s_train_hand = load_images_from_folder(path, -1)\n",
    "\n",
    "\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\train\\attack\\fixed\"\n",
    "replay_img_spoof_train_fixed, replay_label_s_train_fixed = load_images_from_folder(path, -1)\n",
    "\n",
    "replay_img_spoof_train = replay_img_spoof_train_fixed + replay_img_spoof_train_hand \n",
    "replay_label_s_train = replay_label_s_train_fixed + replay_label_s_train_hand\n",
    "\n",
    "replay_img_train = np.array(replay_img_real_train + replay_img_spoof_train)\n",
    "replay_label_train = np.array(replay_label_r_train + replay_label_s_train)\n",
    "\n",
    "\n",
    "\n",
    "# test Dataset real\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\test\\real\"\n",
    "replay_img_real_test, replay_label_r_test = load_images_from_folder(path, 1)\n",
    "\n",
    "# test Dataset attack\n",
    "\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\test\\attack\\hand\"\n",
    "replay_img_spoof_test_hand, replay_label_s_test_hand = load_images_from_folder(path, -1)\n",
    "\n",
    "\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\test\\attack\\fixed\"\n",
    "replay_img_spoof_test_fixed, replay_label_s_test_fixed = load_images_from_folder(path, -1)\n",
    "\n",
    "replay_img_spoof_test = replay_img_spoof_test_fixed + replay_img_spoof_test_hand \n",
    "replay_label_s_test = replay_label_s_test_fixed + replay_label_s_test_hand\n",
    "\n",
    "replay_img_test = np.array(replay_img_real_test + replay_img_spoof_test)\n",
    "replay_label_test = np.array(replay_label_r_test + replay_label_s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder_modified(folder,l):\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = 64\n",
    "    for label in os.listdir(folder):\n",
    "        #for filename in os.listdir(label):\n",
    "\n",
    "        img_path = os.path.join(folder, label) \n",
    "        #os.path.join(label, filename)\n",
    "        \n",
    "        if img_path.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "            img = cv2.resize(cv2.imread(img_path),(size,size))\n",
    "            if img is not None:\n",
    "\n",
    "                images.append(img)\n",
    "                labels.append(l)\n",
    "                    \n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Train Dataset real\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\lcc_fasd_cropped\\LCC_FASD\\LCC_FASD_training\\real\"\n",
    "LCC_img_real_train, LCC_label_r_train = load_images_from_folder_modified(path, 1)\n",
    "\n",
    "# Train Dataset attack\n",
    "\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\lcc_fasd_cropped\\LCC_FASD\\LCC_FASD_training\\spoof\"\n",
    "LCC_img_spoof_train, LCC_label_s_train = load_images_from_folder_modified(path, -1)\n",
    "\n",
    "LCC_img_train = np.array(LCC_img_real_train + LCC_img_spoof_train)\n",
    "LCC_label_train = np.array(LCC_label_r_train + LCC_label_s_train)\n",
    "\n",
    "\n",
    "# test Dataset real\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\lcc_fasd_cropped\\LCC_FASD\\LCC_FASD_evaluation\\real\"\n",
    "LCC_img_real_test, LCC_label_r_test = load_images_from_folder_modified(path, 1)\n",
    "\n",
    "# test Dataset attack\n",
    "\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\lcc_fasd_cropped\\LCC_FASD\\LCC_FASD_evaluation\\spoof\"\n",
    "LCC_img_spoof_test, LCC_label_s_test = load_images_from_folder_modified(path, -1)\n",
    "\n",
    "LCC_img_test = np.array(LCC_img_real_test + LCC_img_spoof_test)\n",
    "LCC_label_test = np.array(LCC_label_r_test + LCC_label_s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder,l):\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = 64\n",
    "\n",
    "    for label in os.listdir(folder):\n",
    "        \n",
    "        label_path = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_path):\n",
    "\n",
    "            for filename in os.listdir(label_path):\n",
    "\n",
    "                img_path = os.path.join(label_path, filename)\n",
    "                if img_path.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "\n",
    "                    img = cv2.resize(cv2.imread(img_path),(size,size))\n",
    "                    if img is not None:\n",
    "\n",
    "                        images.append(img)\n",
    "                        labels.append(l)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Original Faces(Client) with label 1\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\nuaa_cropped\\NUAA\\Detectedface\\ClientFace\"\n",
    "\n",
    "img_real, label_r = load_images_from_folder(path, 1)\n",
    "\n",
    "# Spoof Faces with label -1\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\nuaa_cropped\\NUAA\\Detectedface\\ImposterFace\"\n",
    "img_spoof, label_s = load_images_from_folder(path, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "import numpy as np\n",
    "\n",
    "class LocalBinaryPatterns:\n",
    "    def __init__(self, numPoints, radius):\n",
    "        # store the number of points and radius\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    "        \n",
    "    def lbp_calculate(self, image):\n",
    "        # compute the Local Binary Pattern representation\n",
    "        # of the image, and then use the LBP representation\n",
    "        # to build the histogram of patterns\n",
    "        lbp_image = feature.local_binary_pattern(image, self.numPoints, self.radius, method=\"uniform\")\n",
    "        \n",
    "        lbp_r = np.asarray(np.round(lbp_image)).astype(np.uint8)\n",
    "        return lbp_r\n",
    "\t\n",
    "\n",
    "def plot_histogram(image, if_plot=1):\n",
    "    # Calculate histogram\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "\n",
    "    # Plot histogram\n",
    "    if if_plot==1:\n",
    "        plt.plot(hist)\n",
    "        plt.title('Histogram')\n",
    "        plt.xlabel('Pixel Intensity')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "        \n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Vector Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region(image,n=3):\n",
    "\n",
    "    x = 24\n",
    "\n",
    "    y = 4\n",
    "\n",
    "    #overlapping region  = 24*4 = 96\n",
    "\n",
    "    regions = []\n",
    "\n",
    "    regions.append(image[0:x,0:x])\n",
    "\n",
    "    regions.append(image[x-y:2*x-y,0:x])\n",
    "\n",
    "    regions.append(image[2*x-2*y:,0:x])\n",
    "\n",
    "    regions.append(image[0:x,x-y:2*x-y])\n",
    "\n",
    "    regions.append(image[x-y:2*x-y,x-y:2*x-y])\n",
    "\n",
    "    regions.append(image[2*x-2*y:,x-y:2*x-y])\n",
    "\n",
    "    regions.append(image[0:x,2*x-2*y:])\n",
    "\n",
    "    regions.append(image[x-y:2*x-y,2*x-2*y:])\n",
    "\n",
    "    regions.append(image[2*x-2*y:,2*x-2*y:])\n",
    "\n",
    "\n",
    "    regions = np.array(regions)\n",
    "\n",
    "    return regions\n",
    "\n",
    "\n",
    "def feature_LBP(img1):\n",
    "    size = 64\n",
    "\n",
    "    img  = cv2.cvtColor(cv2.resize(img1,(size,size)), cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "    LBP_1 = LocalBinaryPatterns(8,1)\n",
    "    LBP_2 = LocalBinaryPatterns(8,2)\n",
    "    LBP_3 = LocalBinaryPatterns(16,2)\n",
    "\n",
    "    lbp_img_81 = LBP_1.lbp_calculate(img)\n",
    "   \n",
    "    regions = region(lbp_img_81)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for r in regions:\n",
    "\n",
    "        feature_histogram = plot_histogram(r,0)\n",
    "\n",
    "        features.append(feature_histogram[:10])\n",
    "\n",
    "# Adding the full image image properties\n",
    "        \n",
    "    lbp_img_82 = LBP_2.lbp_calculate(img)\n",
    "    feature_histogram = plot_histogram(lbp_img_82,0)\n",
    "    features.append(feature_histogram[:10])\n",
    "    \n",
    "    lbp_img_162 = LBP_3.lbp_calculate(img)\n",
    "    feature_histogram = plot_histogram(lbp_img_162,0)\n",
    "    features.append(feature_histogram[:10])\n",
    "    \n",
    "    features = (np.array(features)).reshape(110)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPLAY ATTACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing replay dataset train images: 100%|██████████| 3600/3600 [00:09<00:00, 392.84it/s]\n",
      "Processing replay dataset test images: 100%|██████████| 4800/4800 [00:11<00:00, 403.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# FOR REPLAY ATTACK DATASET\n",
    "feature_vec_replay_train = []\n",
    "feature_vec_replay_test = []\n",
    "\n",
    "replay_train_images = replay_img_train\n",
    "replay_test_images = replay_img_test\n",
    "\n",
    "# Loop over images in image_real with tqdm progress bar\n",
    "for img in tqdm(replay_train_images, desc=\"Processing replay dataset train images\"):\n",
    "    feature_vec_replay_train.append(feature_LBP(img))\n",
    "\n",
    "# Loop over images in image_spoof with tqdm progress bar\n",
    "for img in tqdm(replay_test_images, desc=\"Processing replay dataset test images\"):\n",
    "    feature_vec_replay_test.append(feature_LBP(img))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "feature_vector_replay_train = np.array(feature_vec_replay_train)\n",
    "feature_vector_replay_test = np.array(feature_vec_replay_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LCC dataset train images: 100%|██████████| 8746/8746 [00:21<00:00, 401.31it/s]\n",
      "Processing LCC dataset test images: 100%|██████████| 7635/7635 [00:18<00:00, 402.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# FOR LCC DATASET\n",
    "feature_vec_LCC_train = []\n",
    "feature_vec_LCC_test = []\n",
    "\n",
    "LCC_train_images = LCC_img_train\n",
    "LCC_test_images = LCC_img_test\n",
    "\n",
    "# Loop over images in image_real with tqdm progress bar\n",
    "for img in tqdm(LCC_train_images, desc=\"Processing LCC dataset train images\"):\n",
    "    feature_vec_LCC_train.append(feature_LBP(img))\n",
    "\n",
    "# Loop over images in image_spoof with tqdm progress bar\n",
    "for img in tqdm(LCC_test_images, desc=\"Processing LCC dataset test images\"):\n",
    "    feature_vec_LCC_test.append(feature_LBP(img))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "feature_vector_LCC_train = np.array(feature_vec_LCC_train)\n",
    "feature_vector_LCC_test = np.array(feature_vec_LCC_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing real images: 100%|██████████| 5105/5105 [00:12<00:00, 397.75it/s]\n",
      "Processing spoof images: 100%|██████████| 7509/7509 [00:18<00:00, 403.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "feature_vec_real = []\n",
    "feature_vec_spoof = []\n",
    "\n",
    "image_real = img_real\n",
    "image_spoof = img_spoof\n",
    "\n",
    "# Loop over images in image_real with tqdm progress bar\n",
    "for img in tqdm(image_real, desc=\"Processing real images\"):\n",
    "    feature_vec_real.append(feature_LBP(img))\n",
    "\n",
    "# Loop over images in image_spoof with tqdm progress bar\n",
    "for img in tqdm(image_spoof, desc=\"Processing spoof images\"):\n",
    "    feature_vec_spoof.append(feature_LBP(img))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "feature_vectors_real = np.array(feature_vec_real)\n",
    "feature_vectors_spoof = np.array(feature_vec_spoof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Concatenating the Dataset\n",
    "\n",
    "data_set = np.concatenate((feature_vectors_real, feature_vectors_spoof), axis=0)\n",
    "data_set_label = np.concatenate((label_r, label_s),axis=0)\n",
    "\n",
    "# Shuffling teh dataset\n",
    "shuffle_index = np.random.permutation(len(data_set_label))\n",
    "\n",
    "dataset, d_labels = data_set[shuffle_index,:], data_set_label[shuffle_index]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "nuaa_train, nuaa_test, nuaa_label_train, nuaa_label_test = train_test_split(dataset, d_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arranging the dataset\n",
    "\n",
    "NUAA = {\"train_data\":nuaa_train, \"test_data\":nuaa_test, \"train_label\":nuaa_label_train, \"test_label\":nuaa_label_test}\n",
    "LCC = {\"train_data\":feature_vector_LCC_train,\"test_data\":feature_vector_LCC_test,\"train_label\":LCC_label_train,\"test_label\":LCC_label_test}\n",
    "REPLAY = {\"train_data\":feature_vector_replay_train,\"test_data\":feature_vector_replay_test,\"train_label\":replay_label_train,\"test_label\":replay_label_test}\n",
    "data_set = {\"NUAA\":NUAA,\"LCC\":LCC,\"REPLAY\":REPLAY}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each numpy array in each dictionary as .npy files\n",
    "for dataset_name, dataset_content in data_set.items():\n",
    "    for data_name, data_array in dataset_content.items():\n",
    "        np.save(f\"LBP_{dataset_name}_{data_name}.npy\", data_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IVP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
