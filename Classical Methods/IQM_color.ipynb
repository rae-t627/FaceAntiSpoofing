{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage.metrics as sk\n",
    "from sewar.full_ref import vifp\n",
    "from skimage import io, filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FR-IQMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error(MSE)\n",
    "def MSE(img_ref_color, img_color):\n",
    "\n",
    "    mse_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        mse_channel = sk.mean_squared_error(img_ref_color[:,:,i], img_color[:,:,i])\n",
    "        mse_color[i] = (mse_channel)\n",
    "    \n",
    "    mse = np.mean((mse_color))\n",
    "\n",
    "    return mse\n",
    "# Peak Signal to Noise Ratio(PSNR)\n",
    "def PSNR(img_ref_color, img_color):\n",
    "\n",
    "    PSNR_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        PSNR_channel = sk.peak_signal_noise_ratio(img_ref_color[:,:,i], img_color[:,:,i])\n",
    "        PSNR_color[i] = (PSNR_channel)\n",
    "    \n",
    "    PSNR_img = np.mean((PSNR_color))\n",
    "\n",
    "    return PSNR_img\n",
    "\n",
    "# Signal to Noise Ratio(SNR)\n",
    "def SNR(img_ref_color, img_color):\n",
    "\n",
    "    SNR_color = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        power_img = np.mean(np.square(img_ref_color[:,:,i]))\n",
    "\n",
    "        MSE = sk.mean_squared_error(img_ref_color[:,:,i], img_color[:,:,i])\n",
    "\n",
    "        SNR = 10*np.log10(power_img/MSE)\n",
    "\n",
    "        SNR_color[i] = (SNR)\n",
    "    \n",
    "    SNR_img = np.mean((SNR_color))\n",
    "        \n",
    "    return SNR_img\n",
    "# Structural Content(SC)\n",
    "def SC(img_ref_color, img_color):\n",
    "\n",
    "    SC_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        power_ref = np.sum(np.square(img_ref_color[:,:,i]))\n",
    "        power_img = np.sum(np.square(img_color[:,:,i]))\n",
    "\n",
    "        SC_color[i] = (power_ref/power_img)\n",
    "\n",
    "    SC_img = np.mean((SC_color))\n",
    "\n",
    "    return SC_img\n",
    "\n",
    "# Maximum Difference(MD)\n",
    "def MD(img_ref_color, img_color):\n",
    "\n",
    "    MD_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        temp = np.absolute(img_ref_color[:,:,i] - img_color[:,:,i])\n",
    "        MD_color[i] = (np.max(temp))\n",
    "\n",
    "    MD_img = np.mean((MD_color))\n",
    "        \n",
    "    return MD_img\n",
    "\n",
    "# Average Difference(AD)\n",
    "def AD(img_ref_color, img_color):\n",
    "\n",
    "    AD_color = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        AD_color[i] = (np.mean(img_ref_color[:,:,i] - img_color[:,:,i]))\n",
    "    \n",
    "    AD_img = np.mean((AD_color))\n",
    "    \n",
    "    return AD_img\n",
    "\n",
    "# Normalized Absolute Error(NAE)\n",
    "def NAE(img_ref_color, img_color):\n",
    "\n",
    "    NAE_color = np.zeros(3)\n",
    "    for i in range(3):\n",
    "\n",
    "        num = np.sum(np.absolute(img_ref_color[:,:,i] - img_color[:,:,i]))\n",
    "        den = np.sum(np.absolute(img_ref_color[:,:,i]))\n",
    "\n",
    "        NAE_color[i] = (num/den)\n",
    "    NAE_img = np.mean((NAE_color))\n",
    "\n",
    "    return NAE_img\n",
    "\n",
    "# R-Averaged Maximum Difference(RAMD) \n",
    "def RAMD(img_ref_color, img_color, R):\n",
    "\n",
    "    RAMD_color = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        arr = np.sort(np.absolute(img_ref_color[:,:,i] - img_color[:,:,i]), axis=None)\n",
    "        arr1 = arr[-1:-R-1:-1]\n",
    "        RAMD_color[i] = (np.mean(arr1))\n",
    "\n",
    "    RAMD_img = np.mean((RAMD_color))\n",
    "    return RAMD_img\n",
    "\n",
    "# Laplacian Mean Squared Error(LMSE)\n",
    "def LMSE(img_ref_color, img_color):\n",
    "\n",
    "    LMSE_color = np.zeros(3)\n",
    "\n",
    "    for k in range(3):\n",
    "\n",
    "        img_ref = img_ref_color[:,:,k]\n",
    "        img = img_color[:,:,k]\n",
    "\n",
    "        img_ref_pad = np.zeros((img_ref.shape[0]+1,img_ref.shape[1]), dtype=np.int_)\n",
    "        img_pad = np.zeros((img.shape[0]+1,img.shape[1]), dtype=np.int_)\n",
    "\n",
    "        img_ref_pad[1:,:] = img_ref\n",
    "        img_ref_pad[0,:] = img_ref[0,:]\n",
    "        \n",
    "        img_pad[1:,:] = img\n",
    "        img_pad[0,:] = img[0,:]\n",
    "\n",
    "        h_img = np.zeros((img.shape[0]-1, img.shape[1]-2), dtype=np.int_)\n",
    "        h_img_ref = np.zeros((img_ref.shape[0]-1, img_ref.shape[1]-2), dtype=np.int_)\n",
    "\n",
    "        for i in range(img.shape[0]-1):\n",
    "            for j in range(img.shape[1]-2):\n",
    "\n",
    "                h_img[i][j] = img_pad[i+2][j+1] + img_pad[i][j+1] + img_pad[i+1][j] + img_pad[i+1][j+2] - 4*img_pad[i+1][j+1]\n",
    "                h_img_ref[i][j] = img_ref_pad[i+2][j+1] + img_ref_pad[i][j+1] + img_ref_pad[i+1][j] + img_ref_pad[i+1][j+2] - 4*img_ref_pad[i+1][j+1]\n",
    "        \n",
    "        num = np.sum(np.square(h_img_ref - h_img))\n",
    "        den = np.sum(np.square(h_img_ref))\n",
    "    \n",
    "        LMSE_color[k] = (num/den)\n",
    "\n",
    "    LMSE_img = np.mean((LMSE_color))\n",
    "\n",
    "    return LMSE_img\n",
    "\n",
    "# Normalised Cross-Correlation(NXC)\n",
    "def NXC(img_ref_color, img_color):\n",
    "    NXC_color = np.zeros(3)\n",
    "    for i in range(3):\n",
    "\n",
    "        img_ref = img_ref_color[:,:,i]\n",
    "        img = img_color[:,:,i]\n",
    "        num = np.sum(np.multiply(img_ref, img))\n",
    "        den = np.sum(np.square(img_ref))\n",
    "        NXC_color[i]=(num/den)\n",
    "\n",
    "    NXC_img = np.mean(NXC_color)\n",
    "\n",
    "    return NXC_img\n",
    "\n",
    "# Mean Angle Similarity(MAS)\n",
    "def MAS(img_ref, img):\n",
    "\n",
    "    I = img\n",
    "    I_cap = img_ref\n",
    "    \n",
    "    height = I.shape[0]\n",
    "    width = I.shape[1]\n",
    "    s = 0\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            \n",
    "            x   = np.linalg.norm(I[i,j])\n",
    "            y = np.linalg.norm(I_cap[i,j])\n",
    "\n",
    "            if (x!=0) and (y!=0):\n",
    "                alpha = (2*np.dot(I[i,j],I_cap[i,j]))/(np.pi*np.linalg.norm(I[i,j])*np.linalg.norm(I_cap[i,j]))\n",
    "            \n",
    "            else: \n",
    "                alpha = 0\n",
    "            s = s + alpha\n",
    "    \n",
    "    MAS = 1 - (s/(height*width))\n",
    "\n",
    "    return MAS\n",
    "\n",
    "# Mean Angle Magnitude Similarity(MAMS) \n",
    "def MAMS(img_ref, img):\n",
    "\n",
    "    I = img\n",
    "    I_cap = img_ref\n",
    "    \n",
    "    height = I.shape[0]\n",
    "    width = I.shape[1]\n",
    "    s = 0\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            x   = np.linalg.norm(I[i,j])\n",
    "            y = np.linalg.norm(I_cap[i,j])\n",
    "\n",
    "            if (x!=0) and (y!=0):\n",
    "                alpha = (2*np.dot(I[i,j],I_cap[i,j]))/(np.pi*np.linalg.norm(I[i,j])*np.linalg.norm(I_cap[i,j]))\n",
    "            \n",
    "            else: \n",
    "                alpha = 0\n",
    "            mag =1 - ((np.linalg.norm(I[i,j]-I_cap[i,j]))/(np.sqrt(3)*255))\n",
    "            s = s + (1 - ((1-alpha)*mag))\n",
    "    \n",
    "    MAMS = (s/(height*width))\n",
    "\n",
    "    return MAMS\n",
    "\n",
    "# Total Edge Difference(TED)\n",
    "def TED(img_ref_color, img_color):\n",
    "\n",
    "    TED_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "    \n",
    "        img_ref = img_ref_color[:,:,i]\n",
    "        img = img_color[:,:,i]\n",
    "        grad_map_ref = filters.sobel(img_ref)\n",
    "        grad_map = filters.sobel(img)\n",
    "\n",
    "        TED_val = np.sum(np.abs(grad_map-grad_map_ref))\n",
    "\n",
    "        TED_color[i]= (TED_val)\n",
    "\n",
    "    TED_img = np.mean(TED_color)\n",
    "\n",
    "    return TED_img\n",
    "\n",
    "# Total Corner Difference(TCD)\n",
    "def TCD(img_ref_color, img_color):\n",
    "\n",
    "    TCD_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        img_ref = img_ref_color[:,:,i]\n",
    "        img = img_color[:,:,i]\n",
    "        img_ref_32 = np.float32(img_ref)\n",
    "        img_32 = np.float32(img)\n",
    "        \n",
    "        dest_ref = cv2.cornerHarris(img_ref_32, 2, 3, 0.04)\n",
    "        dest = cv2.cornerHarris(img_32, 2, 3, 0.04)\n",
    "        \n",
    "        threshold_ref = 0.01 * dest_ref.max()\n",
    "        threshold = 0.01 * dest.max()\n",
    "\n",
    "        corner_ref_img = np.zeros_like(dest_ref)\n",
    "        corner_img = np.zeros_like(dest)\n",
    "\n",
    "        corner_ref_img[dest_ref > threshold_ref] = 255\n",
    "        corner_img[dest > threshold] = 255\n",
    "\n",
    "        N_cr = np.count_nonzero(corner_ref_img)\n",
    "        N_cap_cr = np.count_nonzero(corner_img)\n",
    "\n",
    "        TCD_val = np.absolute(N_cr - N_cap_cr)/max(N_cr, N_cap_cr)\n",
    "\n",
    "        TCD_color[i]=TCD_val\n",
    "\n",
    "    TCD_img = np.mean(TCD_color)\n",
    "\n",
    "    return TCD_img\n",
    "\n",
    "# Spectral Magnitude Error(SME)\n",
    "def SME(img_ref_color, img_color):\n",
    "\n",
    "    SME_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        img_ref = img_ref_color[:,:,i]\n",
    "        img = img_color[:,:,i]\n",
    "\n",
    "        F_ref = cv2.dft(np.float32(img_ref),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "        F = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "\n",
    "        mag_F_ref = cv2.magnitude(F_ref[:,:,0], F_ref[:,:,1])\n",
    "        mag_F = cv2.magnitude(F[:,:,0], F[:,:,1])\n",
    "\n",
    "        SME_color[i] = np.mean(np.square(mag_F_ref - mag_F))\n",
    "    \n",
    "    SME_img = np.mean(SME_color)\n",
    "\n",
    "    return SME_img\n",
    "\n",
    "# Spectral Phase Error(SPE)\n",
    "def SPE(img_ref_color, img_color):\n",
    "\n",
    "    SPE_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        img_ref = img_ref_color[:,:,i]\n",
    "        img = img_color[:,:,i]\n",
    "        \n",
    "        F_ref = cv2.dft(np.float32(img_ref),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "        F = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "\n",
    "        phase_ref = cv2.phase(F_ref[:,:,0], F_ref[:,:,1], angleInDegrees=False)\n",
    "        phase = cv2.phase(F[:,:,0], F[:,:,1], angleInDegrees=False)\n",
    "\n",
    "        temp = np.square(np.absolute(phase_ref - phase))\n",
    "\n",
    "        SPE_color[i] = np.mean(temp)\n",
    "\n",
    "    SPE_img = np.mean(SPE_color)\n",
    "\n",
    "    return SPE_img\n",
    "\n",
    "# Gradient Magnitude Error(GME)\n",
    "def GME(img_ref_color, img_color):\n",
    "\n",
    "    GME_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        img_ref = img_ref_color[:,:,i]\n",
    "        img = img_color[:,:,i]\n",
    "\n",
    "        G_ref_x = cv2.Sobel(img_ref, cv2.CV_64F, 1, 0)\n",
    "        G_ref_y = cv2.Sobel(img_ref, cv2.CV_64F, 0, 1)\n",
    "        G_ref = np.vectorize(complex)(G_ref_x, G_ref_y)\n",
    "\n",
    "        G_x = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "        G_y = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "        G = np.vectorize(complex)(G_x, G_y)\n",
    "\n",
    "        temp = np.absolute(G_ref) - np.absolute(G)\n",
    "\n",
    "        GME_color[i] = np.mean(np.square(temp))\n",
    "\n",
    "    GME_img = np.mean(GME_color)\n",
    "\n",
    "    return GME_img\n",
    "# Gradient Phase Error(GPE)\n",
    "def GPE(img_ref_color, img_color):\n",
    "\n",
    "    GPE_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        img_ref = img_ref_color[:,:,i]\n",
    "        img = img_color[:,:,i]\n",
    "        \n",
    "        img_ref = cv2.cvtColor(img_ref_color, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "        G_ref_x = cv2.Sobel(img_ref, cv2.CV_64F, 1, 0)\n",
    "        G_ref_y = cv2.Sobel(img_ref, cv2.CV_64F, 0, 1)\n",
    "        G_ref = np.vectorize(complex)(G_ref_x, G_ref_y)\n",
    "\n",
    "        G_x = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "        G_y = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "        G = np.vectorize(complex)(G_x, G_y)\n",
    "        \n",
    "        temp = np.absolute(np.angle(G_ref) - np.angle(G))\n",
    "        GPE_color[i] = np.mean(np.square(temp))\n",
    "\n",
    "    GPE_img = np.mean(GPE_color)\n",
    "    return GPE_img\n",
    "\n",
    "# Structural Similarity Index(SSIM)\n",
    "def SSIM(img_ref_color, img_color):\n",
    "\n",
    "    SSIM_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        img_ref = img_ref_color[:,:,i]\n",
    "        img = img_color[:,:,i]      \n",
    "        SSIM_color[i] =  sk.structural_similarity(img_ref, img)\n",
    "\n",
    "    SSIM_img = np.mean(SSIM_color)\n",
    "\n",
    "   \n",
    "    return SSIM_img\n",
    "\n",
    "# Visual Information Fidelity(VIF)\n",
    "def VIF(img_ref_color, img_color):\n",
    "\n",
    "    VIF_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        img_ref = img_ref_color[:,:,i]\n",
    "        img = img_color[:,:,i]\n",
    "        VIF_color[i] = vifp(img_ref, img)\n",
    "\n",
    "    VIF_img = np.mean(VIF_color)\n",
    "    return VIF_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NR-IQMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPEG Quality Index\n",
    "\n",
    "def measures_JPEG_INDEX(img):\n",
    "\n",
    "    height = int(img.shape[0])\n",
    "    width = int(img.shape[1])\n",
    "\n",
    "    difference_image = np.zeros((height,width-1))\n",
    "\n",
    "    for i in range(height):\n",
    "\n",
    "        for j in range(width-1):\n",
    "\n",
    "            difference_image[i,j] = img[i,j+1] - img[i,j]\n",
    "\n",
    "    B = 0\n",
    "\n",
    "    for i in range(height):\n",
    "\n",
    "        for j in range(0, (int(np.floor(width/8))-1) ):\n",
    "\n",
    "            B = B + np.abs(difference_image[i,8*j])\n",
    "\n",
    "    scaling = 1/(height*((np.floor(width/8))-1))\n",
    "\n",
    "    B_final = scaling*B\n",
    "\n",
    "    A = 0\n",
    "\n",
    "    for i in range(height):\n",
    "\n",
    "        for j in range(0, width-1):\n",
    "\n",
    "            A = A + (np.abs(difference_image[i,j]) - B_final)\n",
    "\n",
    "    scaling = 8/(7*height*(width-1))\n",
    "\n",
    "    A_final = scaling*A\n",
    "\n",
    "    zero_cross = np.zeros((height,width-2))\n",
    "\n",
    "    for i in range(height):\n",
    "\n",
    "        for j in range(0, width-2):\n",
    "\n",
    "            if difference_image[i,j]*difference_image[i,j+1] < 0 :\n",
    "            \n",
    "                zero_cross[i,j] = 1\n",
    "\n",
    "            elif j+2 <= width-2 :\n",
    "\n",
    "                if (difference_image[i,j]*difference_image[i,j+1] == 0) and (difference_image[i,j]*difference_image[i,j+2]< 0):\n",
    "            \n",
    "                    zero_cross[i,j] = 1\n",
    "\n",
    "    Z_final = np.average(zero_cross)\n",
    "\n",
    "    return (B_final,A_final,Z_final)\n",
    "\n",
    "def JPEG_quality_index(img1):\n",
    "\n",
    "    img_color = np.array(img1).astype(int)\n",
    "\n",
    "    JPEG_index_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        img = img_color[:,:,i]\n",
    "\n",
    "        Bh,Ah,Zh = measures_JPEG_INDEX(img)\n",
    "\n",
    "        Bv,Av,Zv = measures_JPEG_INDEX(np.transpose(img))\n",
    "\n",
    "        alpha = -245.9\n",
    "\n",
    "        beta = 261.9\n",
    "\n",
    "        gamma1 = -0.0240\n",
    "\n",
    "        gamma2 = 0.0160\n",
    "\n",
    "        gamma3 = 0.0064\n",
    "\n",
    "        B = 0.5*(Bh + Bv)\n",
    "        A = 0.5*(Ah + Av)\n",
    "        Z = 0.5*(Zh + Zv)\n",
    "\n",
    "        quality_index = alpha + beta*( (B*(gamma1)) + (A*(gamma2)) + (Z*(gamma3)))\n",
    "\n",
    "        JPEG_index_color[i] = quality_index\n",
    "\n",
    "    JPEG_index_img = np.mean(JPEG_index_color)\n",
    "\n",
    "    return JPEG_index_img\n",
    "\n",
    "\n",
    "# High-Low Frequency Index\n",
    "def HLFI(img_color):\n",
    "\n",
    "    HLFI_color = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        img = img_color[:,:,i]      \n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "\n",
    "        i_l = (15*height)//100\n",
    "        j_l = (15*width)//100\n",
    "\n",
    "        F = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "        mag_F = cv2.magnitude(F[:,:,0], F[:,:,1])\n",
    "        mag_F1 = mag_F[:i_l, :j_l]\n",
    "        mag_F2 = mag_F[i_l:, j_l:]\n",
    "\n",
    "        num = np.sum(mag_F1) - np.sum(mag_F2)\n",
    "        den = np.sum(mag_F)\n",
    "\n",
    "        HLFI_color[i] = num/den\n",
    "\n",
    "    HLFI_img = np.mean(HLFI_color)\n",
    "\n",
    "    return HLFI_img\n",
    "\n",
    "# Blind Image Quality Index(BIQI)\n",
    "def BIQI(img):\n",
    "    pass\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector(img):\n",
    "\n",
    "    img_ref = cv2.GaussianBlur(img, (3, 3), 0.5)\n",
    "    vector = []\n",
    "\n",
    "    vector.append(MSE(img, img_ref))\n",
    "    vector.append(PSNR(img, img_ref))\n",
    "    vector.append(SNR(img, img_ref))\n",
    "    vector.append(SC(img, img_ref))\n",
    "    vector.append(MD(img, img_ref))\n",
    "    vector.append(AD(img, img_ref))\n",
    "    vector.append(NAE(img, img_ref))\n",
    "    vector.append(RAMD(img, img_ref, 10))\n",
    "    vector.append(LMSE(img, img_ref))\n",
    "    vector.append(NXC(img, img_ref))\n",
    "    vector.append(MAS(img, img_ref))\n",
    "    vector.append(MAMS(img, img_ref))\n",
    "    vector.append(TED(img, img_ref))\n",
    "    vector.append(TCD(img, img_ref))\n",
    "    vector.append(SME(img, img_ref))\n",
    "    vector.append(SPE(img, img_ref))\n",
    "    vector.append(GME(img, img_ref))\n",
    "    vector.append(GPE(img, img_ref))\n",
    "    vector.append(SSIM(img, img_ref))\n",
    "    vector.append(VIF(img, img_ref))\n",
    "    vector.append(JPEG_quality_index(img))\n",
    "    vector.append(HLFI(img))\n",
    "\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPLAY ATTACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder,l):\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = 64\n",
    "    for label in os.listdir(folder):\n",
    "        \n",
    "        label_path = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_path):\n",
    "\n",
    "            for filename in os.listdir(label_path):\n",
    "\n",
    "                img_path = os.path.join(label_path, filename)\n",
    "                if img_path.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                    \n",
    "                    img = cv2.resize(cv2.imread(img_path),(size,size))\n",
    "                    if img is not None:\n",
    "\n",
    "                        images.append(img)\n",
    "                        labels.append(l)\n",
    "                    \n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Train Dataset real\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\train\\real\"\n",
    "replay_img_real_train, replay_label_r_train = load_images_from_folder(path, 1)\n",
    "\n",
    "# Train Dataset attack\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\train\\attack\\hand\"\n",
    "replay_img_spoof_train_hand, replay_label_s_train_hand = load_images_from_folder(path, -1)\n",
    "\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\train\\attack\\fixed\"\n",
    "replay_img_spoof_train_fixed, replay_label_s_train_fixed = load_images_from_folder(path, -1)\n",
    "\n",
    "replay_img_spoof_train = replay_img_spoof_train_fixed + replay_img_spoof_train_hand \n",
    "replay_label_s_train = replay_label_s_train_fixed + replay_label_s_train_hand\n",
    "\n",
    "replay_img_train = np.array(replay_img_real_train + replay_img_spoof_train)\n",
    "replay_label_train = np.array(replay_label_r_train + replay_label_s_train)\n",
    "\n",
    "# test Dataset real\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\test\\real\"\n",
    "replay_img_real_test, replay_label_r_test = load_images_from_folder(path, 1)\n",
    "\n",
    "# test Dataset attack\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\test\\attack\\hand\"\n",
    "replay_img_spoof_test_hand, replay_label_s_test_hand = load_images_from_folder(path, -1)\n",
    "\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\replay_attack_cropped\\Dataset\\Replay Attack\\Dataset\\test\\attack\\fixed\"\n",
    "replay_img_spoof_test_fixed, replay_label_s_test_fixed = load_images_from_folder(path, -1)\n",
    "\n",
    "replay_img_spoof_test = replay_img_spoof_test_fixed + replay_img_spoof_test_hand \n",
    "replay_label_s_test = replay_label_s_test_fixed + replay_label_s_test_hand\n",
    "\n",
    "replay_img_test = np.array(replay_img_real_test + replay_img_spoof_test)\n",
    "replay_label_test = np.array(replay_label_r_test + replay_label_s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder_modified(folder,l):\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = 64\n",
    "    for label in os.listdir(folder):\n",
    "        #for filename in os.listdir(label):\n",
    "\n",
    "        img_path = os.path.join(folder, label) \n",
    "        #os.path.join(label, filename)\n",
    "        \n",
    "        if img_path.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "            img = cv2.resize(cv2.imread(img_path),(size,size))\n",
    "            if img is not None:\n",
    "\n",
    "                images.append(img)\n",
    "                labels.append(l)\n",
    "                    \n",
    "    return images, labels\n",
    "\n",
    "# Train Dataset real\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\lcc_fasd_cropped\\LCC_FASD\\LCC_FASD_training\\real\"\n",
    "LCC_img_real_train, LCC_label_r_train = load_images_from_folder_modified(path, 1)\n",
    "\n",
    "# Train Dataset attack\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\lcc_fasd_cropped\\LCC_FASD\\LCC_FASD_training\\spoof\"\n",
    "LCC_img_spoof_train, LCC_label_s_train = load_images_from_folder_modified(path, -1)\n",
    "\n",
    "LCC_img_train = np.array(LCC_img_real_train + LCC_img_spoof_train)\n",
    "LCC_label_train = np.array(LCC_label_r_train + LCC_label_s_train)\n",
    "\n",
    "# test Dataset real\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\lcc_fasd_cropped\\LCC_FASD\\LCC_FASD_evaluation\\real\"\n",
    "LCC_img_real_test, LCC_label_r_test = load_images_from_folder_modified(path, 1)\n",
    "\n",
    "# test Dataset attack\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\lcc_fasd_cropped\\LCC_FASD\\LCC_FASD_evaluation\\spoof\"\n",
    "LCC_img_spoof_test, LCC_label_s_test = load_images_from_folder_modified(path, -1)\n",
    "\n",
    "LCC_img_test = np.array(LCC_img_real_test + LCC_img_spoof_test)\n",
    "LCC_label_test = np.array(LCC_label_r_test + LCC_label_s_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder,l):\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = 64\n",
    "\n",
    "    for label in os.listdir(folder):\n",
    "        \n",
    "        label_path = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_path):\n",
    "\n",
    "            for filename in os.listdir(label_path):\n",
    "\n",
    "                img_path = os.path.join(label_path, filename)\n",
    "                if img_path.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "\n",
    "                    img = cv2.resize(cv2.imread(img_path),(size,size))\n",
    "                    if img is not None:\n",
    "\n",
    "                        images.append(img)\n",
    "                        labels.append(l)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Original Faces(Client) with label 1\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\nuaa_cropped\\NUAA\\Detectedface\\ClientFace\"\n",
    "img_real, label_r = load_images_from_folder(path, 1)\n",
    "\n",
    "# Spoof Faces with label -1\n",
    "path = r\"F:\\IVP_Project\\Dataset\\Dataset\\nuaa_cropped\\NUAA\\Detectedface\\ImposterFace\"\n",
    "img_spoof, label_s = load_images_from_folder(path, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Vector Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replay Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing replay dataset train images: 100%|██████████| 3600/3600 [16:48<00:00,  3.57it/s]\n",
      "Processing replay dataset test images: 100%|██████████| 4800/4800 [21:25<00:00,  3.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# FOR REPLAY ATTACK DATASET\n",
    "feature_vec_replay_train = []\n",
    "feature_vec_replay_test = []\n",
    "\n",
    "replay_train_images = replay_img_train\n",
    "replay_test_images = replay_img_test\n",
    "\n",
    "# Loop over images in image_real with tqdm progress bar\n",
    "for img in tqdm(replay_train_images, desc=\"Processing replay dataset train images\"):\n",
    "    feature_vec_replay_train.append(feature_vector(img))\n",
    "\n",
    "# Loop over images in image_spoof with tqdm progress bar\n",
    "for img in tqdm(replay_test_images, desc=\"Processing replay dataset test images\"):\n",
    "    feature_vec_replay_test.append(feature_vector(img))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "feature_vector_replay_train = np.array(feature_vec_replay_train)\n",
    "feature_vector_replay_test = np.array(feature_vec_replay_test)\n",
    "\n",
    "nique_replay_train = np.genfromtxt(r'niqe_train_replay.csv', delimiter=',')\n",
    "nique_replay_test = np.genfromtxt(r'niqe_test_replay.csv', delimiter=',')\n",
    "\n",
    "nique_replay_train = nique_replay_train.reshape((1, nique_replay_train.shape[0]))\n",
    "feature_vector_replay_train = np.concatenate((feature_vector_replay_train, nique_replay_train.T), axis=1)\n",
    "\n",
    "nique_replay_test = nique_replay_test.reshape((1, nique_replay_test.shape[0]))\n",
    "feature_vector_replay_test = np.concatenate((feature_vector_replay_test, nique_replay_test.T), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LCC dataset train images: 100%|██████████| 8746/8746 [36:08<00:00,  4.03it/s]\n",
      "Processing LCC dataset test images: 100%|██████████| 7635/7635 [33:20<00:00,  3.82it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# FOR LCC DATASET\n",
    "feature_vec_LCC_train = []\n",
    "feature_vec_LCC_test = []\n",
    "\n",
    "LCC_train_images = LCC_img_train\n",
    "LCC_test_images = LCC_img_test\n",
    "\n",
    "# Loop over images in image_real with tqdm progress bar\n",
    "for img in tqdm(LCC_train_images, desc=\"Processing LCC dataset train images\"):\n",
    "    feature_vec_LCC_train.append(feature_vector(img))\n",
    "\n",
    "# Loop over images in image_spoof with tqdm progress bar\n",
    "for img in tqdm(LCC_test_images, desc=\"Processing LCC dataset test images\"):\n",
    "    feature_vec_LCC_test.append(feature_vector(img))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "feature_vector_LCC_train = np.array(feature_vec_LCC_train)\n",
    "feature_vector_LCC_test = np.array(feature_vec_LCC_test)\n",
    "\n",
    "nique_LCC_train = np.genfromtxt(r'niqe_train_lcc.csv', delimiter=',')\n",
    "nique_LCC_test = np.genfromtxt(r'niqe_test_lcc.csv', delimiter=',')\n",
    "\n",
    "nique_LCC_train = nique_LCC_train.reshape((1, nique_LCC_train.shape[0]))\n",
    "feature_vector_LCC_train = np.concatenate((feature_vector_LCC_train, nique_LCC_train.T), axis=1)\n",
    "\n",
    "nique_LCC_test = nique_LCC_test.reshape((1, nique_LCC_test.shape[0]))\n",
    "feature_vector_LCC_test = np.concatenate((feature_vector_LCC_test, nique_LCC_test.T), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing real images: 100%|██████████| 5105/5105 [21:00<00:00,  4.05it/s]\n",
      "Processing spoof images: 100%|██████████| 7509/7509 [32:02<00:00,  3.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "feature_vec_real = []\n",
    "feature_vec_spoof = []\n",
    "\n",
    "image_real = img_real\n",
    "image_spoof = img_spoof\n",
    "\n",
    "# Loop over images in image_real with tqdm progress bar\n",
    "for img in tqdm(image_real, desc=\"Processing real images\"):\n",
    "    feature_vec_real.append(feature_vector(img))\n",
    "\n",
    "# Loop over images in image_spoof with tqdm progress bar\n",
    "for img in tqdm(image_spoof, desc=\"Processing spoof images\"):\n",
    "    feature_vec_spoof.append(feature_vector(img))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "feature_vectors_real = np.array(feature_vec_real)\n",
    "feature_vectors_spoof = np.array(feature_vec_spoof)\n",
    "\n",
    "niqe_real = np.genfromtxt(r'niqe_client.csv', delimiter=',')\n",
    "\n",
    "niqe_real = niqe_real.reshape((1, niqe_real.shape[0]))\n",
    "feature_vectors_real = np.concatenate((feature_vectors_real, niqe_real.T), axis=1)\n",
    "\n",
    "niqe_imposter = np.genfromtxt(r'niqe_imposter.csv', delimiter=',')\n",
    "niqe_imposter = niqe_imposter.reshape((1, niqe_imposter.shape[0]))\n",
    "feature_vectors_spoof = np.concatenate((feature_vectors_spoof, niqe_imposter.T), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Concatenating the Dataset\n",
    "\n",
    "data_set = np.concatenate((feature_vectors_real, feature_vectors_spoof), axis=0)\n",
    "data_set_label = np.concatenate((label_r, label_s),axis=0)\n",
    "\n",
    "# Shuffling teh dataset\n",
    "shuffle_index = np.random.permutation(len(data_set_label))\n",
    "\n",
    "dataset, d_labels = data_set[shuffle_index,:], data_set_label[shuffle_index]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "nuaa_train, nuaa_test, nuaa_label_train, nuaa_label_test = train_test_split(dataset, d_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arranging the dataset\n",
    "\n",
    "NUAA = {\"train_data\":nuaa_train, \"test_data\":nuaa_test, \"train_label\":nuaa_label_train, \"test_label\":nuaa_label_test}\n",
    "LCC = {\"train_data\":feature_vector_LCC_train,\"test_data\":feature_vector_LCC_test,\"train_label\":LCC_label_train,\"test_label\":LCC_label_test}\n",
    "REPLAY = {\"train_data\":feature_vector_replay_train,\"test_data\":feature_vector_replay_test,\"train_label\":replay_label_train,\"test_label\":replay_label_test}\n",
    "data_set = {\"NUAA\":NUAA,\"LCC\":LCC,\"REPLAY\":REPLAY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each numpy array in each dictionary as .npy files\n",
    "for dataset_name, dataset_content in data_set.items():\n",
    "    for data_name, data_array in dataset_content.items():\n",
    "        np.save(f\"{dataset_name}_{data_name}.npy\", data_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
